

    \begin{twocolentry}{
        \textit{Remote, United States}    
    
        \textit{Oct 2021 – Oct 2023}}
        \textbf{Lead Data Analyst}
        
        \textit{IQVIA}
    \end{twocolentry}
    


    \vspace{0.10 cm}
    \begin{onecolentry}
        \begin{highlights}
            \item Developed and optimized 20+ ETL pipelines using Azure Data Factory, Databricks, and PySpark, ingesting data from multiple sources, including streaming data via Kafka, and building a scalable data lake solution with ADLS. Enhanced query performance and improved operational efficiency by 20\% while processing \textasciitilde 1 TB data per day.
            \item Orchestrated the development of 14 omni-channel analytical products for pharma client to design ETL using Dataiku, DBT, SQL, Python, and Bitbucket for CI/CD processes. Effectively handled data lakes on AWS S3 and Redshift to support large-scale data operations.
            \item Developed multiple data models in Power BI for analyzing omni-channel campaign impact, customer engagement, feature store, and CRM Insights. Designed interactive dashboards with advanced DAX to track key performance metrics.
            \item Developed and implemented data monitoring systems using SQL and Python, creating custom metrics in Dataiku that significantly improved data quality and reduced issues by 20\% and prevented unwanted pipeline failures.
            \item Led the design and development of a SaaS platform for pharma clients, automating data pipelines and integrating APIs with Python, Java, SQL, and Snowflake, enhancing sales team performance by 15\%. 
            \item Migrated on-premises data warehouse to Snowflake and streamlined data ingestion processes by utilizing SnowPipe with Azure Blob Storage, enhancing scalability and ensuring efficient, automated pipeline operations. 
            
            \textbf{Technologies Used:} Azure, Snowflake, Redshift, Dataiku, Databricks, Kafka, SQL, Python, PySpark, Power BI.
        \end{highlights}
    \end{onecolentry}



    
    \vspace{0.2 cm}

    \begin{twocolentry}{
        \textit{Remote, Norway}    
    
        \textit{Feb 2020 – Sep 2021}}
        \textbf{Senior Data Analyst}
        
        \textit{Cefalo}
    \end{twocolentry}
    
    \vspace{0.10 cm}
    \begin{onecolentry}
        \begin{highlights}
            \item Developed a data mash and automated social media analytics dashboards in Power BI for an oil shipping company, by integrating data in AWS Glue from Google Analytics, Facebook, Instagram, and LinkedIn. This initiative resulted in an estimated savings of \textasciitilde\$600K per year in branding budgets.
            \item Developed Azure data pipeline using Databricks, Snowflake and Synapse Analytics for reporting solutions, reducing latency and improving decision-making.
            \item Engineered Azure-based data pipelines using Ariflow for reports like Subscription KPI, Sales Retention, and Revenue tracking, resulting in a 20\% improvement in customer retention strategies.
            \item Automated Qlik Sense reporting for Revenue, Subscription, and Corporate Overview analysis, increasing financial planning accuracy by 25\%.
            \item Collaborated on scalable reporting solutions in Qlik Sense for customer acquisition and churn analysis using Azure Synapse, improving customer behavior insights.
    
            \textbf{Technologies Used:} Azure, AWS, Databricks, Snowflake, SSIS, Airflow, Qlik Sense, Power BI, SQL, Python.
         \end{highlights}
    \end{onecolentry}



    \vspace{0.2 cm}

    \begin{twocolentry}{
        \textit{Remote, United States}    
    
        \textit{Feb 2015 – Jan 2020}}
        \textbf{Senior Data Analyst}
        
        \textit{IQVIA}
    \end{twocolentry}
    
    \vspace{0.10 cm}
    \begin{onecolentry}
        \begin{highlights}   
            \item Migrated an on-premises ETL pipeline to Azure Data Factory for a pharma client, integrating data from the Orchestrated Customer Engagement (OCE) in the Salesforce system using SQL, reducing data processing time from 9 hours to 1.5 hours and saving the client \textasciitilde\$155K annually by enhancing performance.
            \item Designed tabular data model in SSIS, SSAS with RLS for Power BI CRM reporting, integrating data from Salesforce CRM API and orchestrating a data pipeline in MS SQL Server, supporting 7 different comprehensive report development.
            \item Created a comprehensive sales dashboard with 10 years history in QlikView with 3-tier architecture and Teradata for multiple Europe region, improving sales performance tracking by 20\%.
            \item Automated 80\% of Pricing Insight processes using SSIS, SSRS, and SQL, improving data quality and generating monthly reports, while managing data production across 40 European countries for 10+ clients.
            \item Delivered SSAS cubes weekly and monthly, processing data in MS SQL Server using SQL, Python, and R to calculate pharmaceutical prices and sales.
            
            \textbf{Technologies Used:} Python, SQL, R, Power BI, QlikView, Qlik Sense, SSAS, SSIS, SSRS, SSMS, Azure Data Factory and blob storage.
        \end{highlights}
    \end{onecolentry}


    \vspace{0.2 cm}       


    \begin{twocolentry}{
        \textit{Dhaka, Bangladesh}    
    
        \textit{Nov 2013 – Jan 2015}}
        \textbf{Data Analyst}
        
        \textit{Bangladesh Centre for Advanced Studies}
    \end{twocolentry}
    
    \vspace{0.10 cm}
    \begin{onecolentry}
        \begin{highlights}
            \item Played a pivotal role in identifying research topics and crafting proposals that secured two major projects, driving research initiatives forward and delivering impactful scientific insights for stakeholders.
            \item Leveraged data analysis tools like R, SPSS, Excel, and MS Access to process and analyze complex datasets, providing actionable insights that shaped project strategies and facilitated successful donor reporting.
        \end{highlights}
    \end{onecolentry}

